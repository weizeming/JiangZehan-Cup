{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "12c1dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ACLScheduleTest.Simulate import Simulator\n",
    "from ACLScheduleTest.Analysis import Analyst\n",
    "from ACLScheduleTest.data import RandomDsk\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "rd = RandomDsk(\n",
    "    mute=True, node_num=100,\n",
    "    st_node_num=10,\n",
    "    min_time=1, time_lv=0, time_rv=0, min_time_step=0,\n",
    "    avg_mem_peek=1, mem_pv=0, mem_sv=1\n",
    ")\n",
    "dsk = rd.build()\n",
    "sim = Simulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684dcc5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c0d53162",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_workers, num_nodes = 10, 100\n",
    "\n",
    "information = np.ones((num_nodes, num_workers))\n",
    "def topoOrder(workers, cache, av_mem, factor_node_dict, calculated_node_dict, dsk, global_dict):\n",
    "    topoQueue = []\n",
    "    matrix = np.zeros((num_nodes, num_nodes))\n",
    "    nodeList = list(dsk.keys())\n",
    "    for idx, node in enumerate(nodeList):\n",
    "        for n in dsk[node][1:]:\n",
    "            if n in nodeList:\n",
    "                id = nodeList.index(n)\n",
    "                matrix[idx, id] = 1 # idx depends on id\n",
    "    while len(topoQueue) < len(nodeList):\n",
    "        for idx, node in enumerate(nodeList):\n",
    "            if node in topoQueue:\n",
    "                continue\n",
    "            if matrix[idx].sum() == 0:\n",
    "                topoQueue.append(node)\n",
    "                matrix[:, idx] = 0\n",
    "    return topoQueue\n",
    "\n",
    "import math\n",
    "def reward(x):\n",
    "    baseline = 5\n",
    "    return math.exp(x - baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190fd5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63740960",
   "metadata": {},
   "source": [
    "## Ant as Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e72c2e2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "current_worker_id = 0\n",
    "iter = 0\n",
    "from schedule_func_backup import schedule_out_func\n",
    "def search(dsk):\n",
    "    global current_worker_id, iter\n",
    "    current_worker_id, iter = 0, 0\n",
    "    worker_schedules = []\n",
    "    worker_traces = np.zeros((num_nodes, num_workers))\n",
    "    for idx in range(num_workers):\n",
    "        worker_schedule = [idx]\n",
    "        worker_schedules.append(worker_schedule)\n",
    "        worker_traces[idx, idx] = 1\n",
    "    for node_id in range(num_workers, num_nodes):\n",
    "        prob = information[node_id] / information[node_id].sum()\n",
    "        select_worker = np.random.choice(range(num_workers), p=prob)\n",
    "        worker_schedules[select_worker].append(node_id)\n",
    "        worker_traces[node_id, select_worker] = 1\n",
    "    #print(worker_schedules)\n",
    "    def search_n_func(workers, cache, av_mem, factor_node_dict, calculated_node_dict, dsk, global_dict):\n",
    "        global current_worker_id, iter\n",
    "        ori_id = current_worker_id\n",
    "\n",
    "        current_worker_id += 1\n",
    "        if current_worker_id >= num_workers:\n",
    "            current_worker_id = 0\n",
    "            iter += 1\n",
    "            #print(f'\\niter {iter}')\n",
    "        #print(current_worker_id)\n",
    "        if av_mem == 0:\n",
    "            return None\n",
    "        if len(worker_schedules[ori_id])==0:\n",
    "            return None\n",
    "        node_id = worker_schedules[ori_id][0]\n",
    "        node = f'node{node_id}'\n",
    "        nodeList = set(dsk.keys())\n",
    "        #print(node)\n",
    "\n",
    "        pre_nodes = [arg for arg in dsk[node][1:] if arg in nodeList]\n",
    "        #print(pre_nodes)\n",
    "        for arg in pre_nodes:\n",
    "            if arg in nodeList and arg not in cache.keys():\n",
    "                #print('None\\n', '-'*100)\n",
    "                return None\n",
    "        worker_schedules[ori_id].remove(node_id)\n",
    "        #print(node, '\\n', '-'*100)\n",
    "        return node\n",
    "\n",
    "    result = sim.simulate(search_n_func, schedule_out_func, mem_bound=50, worker_bound=10,dsk=dsk,rd=rd, compare_mode=True)\n",
    "    analyst = Analyst()\n",
    "    sucess_rate, speed_up = analyst.run(result=[[result]])\n",
    "    speed_up = speed_up.values.item()\n",
    "    rewarded = np.array([reward(speed_up)]) * sucess_rate\n",
    "    return speed_up, rewarded * worker_traces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "3c4f81cd",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "76b32847",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: speed_up = 5.274. Use time: 11.021054983139038\n",
      "epoch 2: speed_up = 5.445. Use time: 10.648623943328857\n",
      "epoch 3: speed_up = 5.626. Use time: 10.647620916366577\n",
      "epoch 4: speed_up = 5.876. Use time: 9.904424905776978\n",
      "epoch 5: speed_up = 5.882. Use time: 9.708353042602539\n",
      "epoch 6: speed_up = 5.882. Use time: 10.11555004119873\n",
      "epoch 7: speed_up = 5.882. Use time: 9.555318832397461\n",
      "epoch 8: speed_up = 5.882. Use time: 9.5466628074646\n",
      "epoch 9: speed_up = 5.882. Use time: 9.926537990570068\n",
      "epoch 10: speed_up = 5.882. Use time: 9.721480369567871\n",
      "epoch 11: speed_up = 5.882. Use time: 9.839972019195557\n",
      "epoch 12: speed_up = 5.882. Use time: 9.602741956710815\n",
      "epoch 13: speed_up = 5.882. Use time: 9.579833030700684\n",
      "epoch 14: speed_up = 5.882. Use time: 9.581772089004517\n",
      "epoch 15: speed_up = 5.882. Use time: 9.568605184555054\n",
      "epoch 16: speed_up = 5.882. Use time: 9.672024965286255\n",
      "epoch 17: speed_up = 5.882. Use time: 9.660619020462036\n",
      "epoch 18: speed_up = 5.882. Use time: 9.7033531665802\n",
      "epoch 19: speed_up = 5.882. Use time: 9.642760038375854\n",
      "epoch 20: speed_up = 5.882. Use time: 9.736347913742065\n"
     ]
    }
   ],
   "source": [
    "rd = RandomDsk(mute=True)\n",
    "def train(num_epochs, num_agent, alpha):\n",
    "    global  information\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time()\n",
    "        new_information = np.zeros((num_nodes, num_workers))\n",
    "        speed_up_total = 0\n",
    "        for agent_idx in range(num_agent):\n",
    "            speed_up , rewarded = search(dsk)\n",
    "            new_information += rewarded\n",
    "            speed_up_total += speed_up\n",
    "            information = alpha * information + new_information\n",
    "        print(f'epoch {epoch+1}: speed_up = {speed_up_total / num_agent:.3f}. Use time: {time()-start_time}')\n",
    "train(20, 50, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f87860",
   "metadata": {},
   "source": [
    "## schedule_in_func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e05501ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21282720",
   "metadata": {},
   "source": [
    "## schedule_out_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcb311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea512f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce40a07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491d210",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724be8fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}